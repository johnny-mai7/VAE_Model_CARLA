# ğŸš— VAE-Based OOD Detection for Autonomous Driving

![CARLA Simulation](https://upload.wikimedia.org/wikipedia/commons/3/36/CARLA_Simulator.png)  
*A deep learning approach to Out-of-Distribution (OOD) detection in self-driving systems using multi-modal sensor data.*

---

## ğŸ“Œ Overview
This project leverages a **Variational Autoencoder (VAE)** to detect **Out-of-Distribution (OOD) data** in an autonomous driving scenario simulated in **CARLA**. The system integrates **camera, LiDAR, radar, and vehicle state data**, preprocesses them, and trains a VAE model to distinguish between normal and anomalous driving conditions. If OOD data is detected, the **vehicle switches to manual driving mode** to prevent failures.

---

## ğŸ“‚ Project Structure
ğŸ“¦ OOD_Detection â”œâ”€â”€ ğŸ“ scripts â”‚ â”œâ”€â”€ collect_data.py # Collects multi-modal sensor data from CARLA 
â”‚ â”œâ”€â”€ preprocess_images.py # Converts and normalizes camera images into .npy format â”‚ â”œâ”€â”€ ensure_sequential_filenames.py # Ensures all files are numbered correctly â”‚ â”œâ”€â”€ combine_multimodal_data.py # Merges all sensor modalities into a single dataset â”‚ â”œâ”€â”€ train_vae.py # Trains the Variational Autoencoder â”‚ â”œâ”€â”€ reconstruction_test.py # Evaluates model reconstruction performance â”‚ â”œâ”€â”€ debug_file_check.py # Checks dataset integrity across all levels â”‚ â”œâ”€â”€ missing_data.py # Identifies missing samples in each level â”œâ”€â”€ ğŸ“ preprocessed â”‚ â”œâ”€â”€ ğŸ“ camera_npy/ # Preprocessed camera images in .npy format â”‚ â”œâ”€â”€ ğŸ“ lidar/ # Processed LiDAR data â”‚ â”œâ”€â”€ ğŸ“ radar/ # Processed radar data â”‚ â”œâ”€â”€ ğŸ“ vehicle_state/ # Processed vehicle state logs â”‚ â”œâ”€â”€ combined_data.npy # Final multi-modal dataset for training â”œâ”€â”€ ğŸ“ models â”‚ â”œâ”€â”€ vae_model.pth # Trained VAE model â”œâ”€â”€ README.md
